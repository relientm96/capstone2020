# Real-time translation of Auslan using pose estimation

## Problem Statement
-   Mute or deaf people are excluded from conversations from people who do not know sign language
-   There are no portable and accessible solutions for the general population
    -   Proprietary products only available + non accessible 

## Project Summary and Objectives
-   We want to provide an accessible communication platform for people with disabilities to interact
-   Build an application either on laptop or mobile that does real time pose estimation that translates poses/gestures into text and ultimately to speech.

## Pros

## Cons

## Project description and idea of tasks
-   Identify a pose/gesture recognition system that would be able to do pose estimation in real-time.
-   Figure out a way to recognize different sign gestures (probably using machine learning/neural network)
-   Hook the output (gestures recognized) of the above system to a real-time speech generation software.
-   If time permits, build an API/GUI for people to map their own gesture.
