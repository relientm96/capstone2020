Here is one of my proposals...
More references coming soon...

# Real-time translation of Auslan using pose estimation
## Motivation
To provide a platform where people using Auslan could participate in conversations with poeple whom cannot use Auslan
## Goal
To build an application that would translate sign language into text and voice in real time
## Project description and idea of tasks
-   Identify a pose/gesture recognition system that would be able to do pose estimation in real-time.
-   Figure out a way to recognize different sign gestures (probably using machine learning/neural network)
-   Hook the output (gestures recognized) of the above system to a real-time speech generation software.
-   If time permits, build an API/GUI for people to map their own gesture.
## Reasons to backup
-   Not much
-   The project goal seems to be meaningful
-   By the end of this, we will all be familiar with the basics of machine learning.
-   Feel free to approve/disapprove...
